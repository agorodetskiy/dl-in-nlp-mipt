{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anarchism', 'originated', 'as', 'a', 'term']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./dataset/corpus', 'rt') as fp:\n",
    "    corpus = fp.read()\n",
    "\n",
    "corpus = corpus.strip()\n",
    "corpus = corpus.split()\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramBatcher:\n",
    "    def __init__(self, corpus, window_size=4, batch_size=32):\n",
    "        '''corpus - list of words'''\n",
    "        self.corpus = corpus\n",
    "        self.window_size = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.make_vocab()\n",
    "        return\n",
    "    \n",
    "    def make_vocab(self):\n",
    "        self.vocab = sorted(set(corpus))\n",
    "        self.word2index = {w: idx for idx, w in enumerate(self.vocab)}\n",
    "        self.index2word = {idx: w for idx, w in enumerate(self.vocab)}\n",
    "        return\n",
    "    \n",
    "    def batch_gen(self):\n",
    "        '''c - corpus, v - vocab ; i - central, j - side'''\n",
    "        x_batch = np.empty(self.batch_size, dtype=np.int)\n",
    "        y_batch = np.empty(self.batch_size, dtype=np.int)\n",
    "        curr_idx = 0\n",
    "        for c_i, w in enumerate(self.corpus):\n",
    "            v_i = self.word2index[w]\n",
    "            window_left_border = c_i - self.window_size\n",
    "            if window_left_border < 0:\n",
    "                window_left_border = 0\n",
    "            for side_w in self.corpus[window_left_border: c_i] \\\n",
    "                          + self.corpus[c_i + 1 : c_i + self.window_size + 1]:\n",
    "                v_j = self.word2index[side_w]\n",
    "                x_batch[curr_idx] = v_i\n",
    "                y_batch[curr_idx] = v_j\n",
    "                curr_idx += 1\n",
    "                if curr_idx == self.batch_size:\n",
    "                    curr_idx = 0\n",
    "                    yield (x_batch, y_batch)\n",
    "        # drop last\n",
    "        #if curr_idx != 0:\n",
    "            #yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_filter(corpus, threshold):\n",
    "    freq_map = Counter(corpus)\n",
    "    filtrator = lambda w: 'UNK' if freq_map[w] <= threshold else w\n",
    "    corpus = map(filtrator, corpus)\n",
    "    return list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011120887855114024"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = freq_filter(corpus, 2)\n",
    "corpus.count('UNK') / len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = SkipGramBatcher(corpus, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking batches' shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_batch.shape: (32,), y_batch.shape: (32,)\n",
      "x_batch.shape: (32,), y_batch.shape: (32,)\n",
      "x_batch.shape: (32,), y_batch.shape: (32,)\n",
      "x_batch.shape: (32,), y_batch.shape: (32,)\n",
      "x_batch.shape: (32,), y_batch.shape: (32,)\n"
     ]
    }
   ],
   "source": [
    "max_iter = 5\n",
    "for x_batch, y_batch in islice(batcher.batch_gen(), max_iter):\n",
    "    print('x_batch.shape: {}, y_batch.shape: {}'.format(x_batch.shape, y_batch.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print generated batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english']\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "anarchism originated\n",
      "anarchism as\n",
      "anarchism a\n",
      "anarchism term\n",
      "originated anarchism\n",
      "originated as\n",
      "originated a\n",
      "originated term\n",
      "originated of\n",
      "as anarchism\n",
      "as originated\n",
      "as a\n",
      "as term\n",
      "as of\n",
      "as abuse\n",
      "a anarchism\n",
      "a originated\n",
      "a as\n",
      "a term\n",
      "a of\n",
      "a abuse\n",
      "a first\n",
      "term anarchism\n",
      "term originated\n",
      "term as\n",
      "term a\n",
      "term of\n",
      "term abuse\n",
      "term first\n",
      "term used\n",
      "of originated\n",
      "of as\n",
      "----------------------\n",
      "of a\n",
      "of term\n",
      "of abuse\n",
      "of first\n",
      "of used\n",
      "of against\n",
      "abuse as\n",
      "abuse a\n",
      "abuse term\n",
      "abuse of\n",
      "abuse first\n",
      "abuse used\n",
      "abuse against\n",
      "abuse early\n",
      "first a\n",
      "first term\n",
      "first of\n",
      "first abuse\n",
      "first used\n",
      "first against\n",
      "first early\n",
      "first working\n",
      "used term\n",
      "used of\n",
      "used abuse\n",
      "used first\n",
      "used against\n",
      "used early\n",
      "used working\n",
      "used class\n",
      "against of\n",
      "against abuse\n"
     ]
    }
   ],
   "source": [
    "i2w = batcher.index2word\n",
    "gen = batcher.batch_gen()\n",
    "\n",
    "# printing 2 sequential batches\n",
    "for _ in range(2):\n",
    "    x_ids, y_ids = next(gen)\n",
    "    print('----------------------')\n",
    "    for x_w, y_w in [(i2w[i], i2w[j]) for i, j in zip(x_ids, y_ids)]:\n",
    "        print(x_w, y_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">*clean code*</span>         <------        ( in case you've lost it )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
